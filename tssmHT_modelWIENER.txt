model {

    # Mean estimates of the linear regressions for the weights
        b1.mu[c] ~ dunif(-5,5) # td
        b2.mu[c] ~ dunif(-5,5) # hd
        
	# precisions for the linear regression estimates
        b1.pr[c] ~ dgamma(1, 0.1)
        b2.pr[c] ~ dgamma(1, 0.1)
        
	# mean estimates DDM parameters
        alpha.mu[c] ~ dunif(0.001, 1) # noise
        theta.mu[c] ~ dunif(0, 10) # non decision times

	# Error terms for nDT
        alpha.pr[c] ~ dgamma(1, 0.1)
        theta.pr[c] ~ dgamma(1, 0.1)


    # error term for the regression function
        e.sG[c] <- pow(e.m[c],2) / pow(e.d[c],2)
        e.rG[c] <- e.m[c] / pow(e.d[c],2)
        e.m[c] ~ dgamma(1,0.2)T(0.001,20)
        e.d[c] ~ dgamma(1,0.5)T(0.001,20)


    # error term for the bias
        lambda.sG[c] <- pow(lambda.m[c],2) / pow(lambda.d[c],2)
        lambda.rG[c] <- lambda.m[c] / pow(lambda.d[c],2)
        lambda.m[c] ~ dgamma(1,0.2)T(0.001,20)
        lambda.d[c] ~ dgamma(1,0.5)T(0.001,20)

    # error term for nDT
        chi.sG[c] <- pow(chi.m[c],2) / pow(chi.d[c],2)
        chi.rG[c] <- chi.m[c] / pow(chi.d[c],2)
        chi.m[c] ~ dgamma(1,0.2)T(0.001,20)
        chi.d[c] ~ dgamma(1,0.5)T(0.001,20)

    # Bias of the DDM
        bias.alpha[c] <- bias.mu[c] * bias.kappa[c]
        bias.beta[c] <- (1 - bias.mu[c]) * bias.kappa[c]
        bias.mu[c] ~ dbeta(2, 2)T(0.01,0.99)
        bias.kappa[c] ~ dgamma(1, 0.5)

    # timeIn of the DDM (positive b2 comes first and b1 comes at time timeIn, negative the opposite)
        time.mu[c] ~ dunif(-5,5)
        time.pr[c] ~ dgamma(1, 0.01)


    for (p in 1:ns) { # subject level

        b1.p[p] ~ dnorm(b1.mu, b1.pr)
        b2.p[p] ~ dnorm(b2.mu, b2.pr)

        time[p] ~ dnorm(time.mu, time.pr)

        alpha.p[p] ~ dnorm(alpha.mu, alpha.pr)
        theta.p[p] ~ dnorm(theta.mu, theta.pr)
        e.p.tau[p] ~ dgamma(e.sG, e.rG)T(0.001,20)
        chi.p.tau[p] ~ dgamma(chi.sG, chi.rG)T(0.001,20)
        lambda.p.tau[p] ~ dgamma(lambda.sG, lambda.rG)T(0.001,20)
        bias[p] ~ dbeta(bias.alpha, bias.beta)T(0.01,0.99)
    }

    for (i in 1:N) { # trial level

## WIENER model, fixing the threshold to 2 and estimating the noise
        y[i] ~ dwieners(2 , tau[i], bet[i], w[i], alpha.p[idxP[i]]) # actual DDM distribution

        # generate predictions
        y_pred[i] ~ dwieners(2 , tau[i], bet[i], w[i], alpha.p[idxP[i]])

        # generate trial-by-trial nDT
          tau[i] <- theta.p[idxP[i]]
          dT[i] <- rt[i] - tau[i]

        # generate trial-by-trial Bias
          bet[i] <- bias[idxP[i]]

        # The actual drift rate
          w[i] ~ dnorm(li.hat[i], e.p.tau[idxP[i]])

        # rt minus timeHin
          timeStep[i] <- (dT[i] - timeIn[i])/dT[i]    #time is a weighted variable depending when the health(b1) or taste(b2) comes first
          smaller[i] <- step(timeStep[i])             #if smaller==0 either health or taste doesnt get in, the timeIn > (rt+ndt)


        li.hat_h[i] <- (1-s[i]) * vd_h[i] +   s[i]   * ( smaller[i] * timeStep[i] * vd_h[i] )
        li.hat_t[i] <-    s[i]  * vd_t[i] + (1-s[i]) * ( smaller[i] * timeStep[i] * vd_t[i] )

        li.hat[i] <- li.hat_h[i] + li.hat_t[i]

        # The linear regression of the value taste and value health
          vd_h[i] <-  b1.p[idxP[i]] * hd[i]
          vd_t[i] <-  b2.p[idxP[i]] * td[i]

          timeIn[i] <- abs(time[idxP[i]])
          s[i] <- step(time[idxP[i]])

    }
}
